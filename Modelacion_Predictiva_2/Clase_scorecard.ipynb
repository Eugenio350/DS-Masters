{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de modelos de puntuación del Riesgo de Impago\n",
    "\n",
    "En esta aplicación implementaremos un modelo de puntuación de riesgo de impago siguiendo la metodología  que hemos analizado en la presentación de clase (selección de variables mediante valor de la información, tramificación de variables continuas, agrupación de categorías, transformación woe de variables, estimación de modelos de regresión logística, ....)\n",
    "\n",
    "Existen diferentes librerías que incorporan funciones con los diferentes procedimientos ya programados que nos facilitan mucho la tarea. Una de estas librerías es `scorecardpy` [librería scorecardpy](https://pypi.org/project/scorecardpy/) que estima tarjetas de puntuación *lineales* utilizando regresiones logísticas. Esta librería nació inicialmente en R, y lamentablemente la versión de Python da algunos errores de adaptación a las últimas versiones de Pandas. Su desarrollador remite a utilizar la versión estable de R (librería en R 'scorecard'). \n",
    "\n",
    "Así que en su lugar de esta librería utilizaremos la librería `optBinning` [librería OptBinning](http://gnpalencia.org/optbinning/) que en realidad recoge (y en mi opinión mejora) la principal función de la librería `scorecardpy`  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de un entorno e instalación de librerías \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos Crear un nuevo entorno de trabajo (mejor desde el terminal)\n",
    "#! conda create -n risk_env\n",
    "#! conda activate risk_env\n",
    "#! conda config --env --add channels conda-forge\n",
    "#! conda config --env --set channel_priority strict\n",
    "\n",
    "# Instalamos la librería pandas y seaborn en el nuevo entrono desde conda (sólo la primera vez, utilizaré el terminal (con jupiter debo utilizar !))\n",
    "# conda install pandas\n",
    "# conda install seaborn\n",
    "\n",
    "# Instalamos la librería optbinning y scorecardpy (sólo la primera vez)\n",
    "# ! pip install scorecardpy # NOOO esta no la intaleis porque no es estable\n",
    "# ! pip install optbinning\n",
    "\n",
    "\n",
    "#Cargo o importo pandas, numpy, Matplotlib, \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Para el análisis descriptivo inicial de contraste de asociación importo el test Chi2 y el anova \n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Cargaríamos la librería scortecardpy si fuese estable (que no lo es)\n",
    "#import scorecardpy as sc\n",
    "\n",
    "\n",
    "# Librería para hacer la tramificación, agrupación y transformación WOE\n",
    "from optbinning import Scorecard, BinningProcess, OptimalBinning\n",
    "from optbinning.scorecard import plot_auc_roc, plot_cap, plot_ks\n",
    "\n",
    "\n",
    "# Scikit-learn para dividir la muestra y para estimar el modelo de regresión logística (sólo si no se quiere utilizar\n",
    "# la función optbinning.scorecard que ya lo incropora)\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de los datos sobre Créditos que utilizaremos en la práctica **germancredit**\n",
    "## Carga de los datos \n",
    "En nuestra práctica utilizaremos una de las bases más utilizadas en los ejemplos de Puntuación de riesgo de crédito porque fue una de las primeras en ofrecerse en abierto. Corresponden a una base de datos de créditos de un Banco Alemán, y son datos reales, aunque muy antigüos de principios de los 90. Eso significa que las magnitudes de cantidades (expresadas en Marcos Alemanes), sean de difícil interpretación para el día de hoy. Sin embargo el signo y el sentido de las variables utilizadas para predecir el riesgo de impago de los futuros clientes permanece todavía de plena utilidad.\n",
    "\n",
    "Los datos pueden descargarse del repositorio la UCI Machine Learning Repositoy [datos de Créditos alemanes](https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)). Esta base de datos está incorporada en la librería `sorecardpy` pero mejor utilizamos el fichero original `germancredit.csv` que os he preparado yo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos germancredit que están precargados en la librería scorecardpy\n",
    "dt=pd.read_csv('germancredit.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción inicial de los datos\n",
    "Vamos a hacer una descripción inicial de los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Información del Contenido\n",
    "dt.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable objetivo: creditability\n",
    "\n",
    " La variable **creditability** es la *calidad crediticia* de  cada cliente, es la variable a predecir.    \n",
    " Toma originalmente dos valores (Buen Cliente y Mal Clioente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"creditability\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recodifico esta variable creditability para que sea binaria y la llamo \"y\"\n",
    "\n",
    "dt.rename(columns={\"creditability\":\"y\"},inplace=True)\n",
    "dt['y'] = dt['y'].replace(['good', 'bad'], [0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"y\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# También elimino la primera columna que no debería estar (es una variable de identificación que no debería tener en cuenta para la estimación del modelo)\n",
    "dt.drop(labels='Unnamed: 0',inplace=True, axis=1)\n",
    "\n",
    "dt.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Predictoras o explicativas\n",
    "\n",
    "Las 20 restantes variables del data frame (7 numéricas y 13 categóricas) son los atributos o características observadas de esos clientes que se utilizarán para predecir la probabilidad de que los clientes cometan un impago de sis créditos, esto es, de que sean malos clientes. La descripción de estas 20 variables es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  - Attribute 1: (qualitative) **Status of existing checking account o cuenta corriente** \n",
    "#   - A11 : ... < 0 DM \n",
    "#   - A12 : 0 <= ... < 200 DM \n",
    "#   - A13 : ... >= 200 DM / salary assignments for at least 1 year \n",
    "#   - A14 : no checking account \n",
    "\n",
    "#- Attribute 2: (numerical) **Duration in month** \n",
    "  \n",
    "#  - Attribute 3: (qualitative) **Credit history**  \n",
    "#     - A30 : no credits taken/ all credits paid back duly (devultos sin mora)\n",
    "#     - A31 : all credits at this bank paid back duly \n",
    "#     - A32 : existing credits paid back duly till now \n",
    "#     - A33 : delay in paying off in the past \n",
    "#     - A34 : critical account/ other credits existing (not at this bank) \n",
    "\n",
    "# - Attribute 4: (qualitative) **Purpose** \n",
    "#     - A40 : car (new) \n",
    "#     - A41 : car (used)\n",
    "#     - A42 : furniture/equipment\n",
    "#     - A43 : radio/television\n",
    "#     - A44 : domestic appliances\n",
    "#     - A45 : repairs\n",
    "#     - A46 : education\n",
    "#     - A47 : (vacation - does not exist?)\n",
    "#     - A48 : retraining\n",
    "#     - A49 : business\n",
    "#    - A410 : others \n",
    "\n",
    "# - Attribute 5: (numerical) **Credit amount** \n",
    "  \n",
    "# - Attribute 6: (qualitative) **Savings account/bonds** \n",
    "#    - A61 : ... < 100 DM\n",
    "#    - A62 : 100 <= ... < 500 DM\n",
    "#    - A63 : 500 <= ... < 1000 DM\n",
    "#    - A64 : .. >= 1000 DM \n",
    "#    - A65 : unknown/ no savings account \n",
    "\n",
    "# - Attribute 7: (qualitative) **Present employment since** \n",
    "#     - A71 : unemployed \n",
    "#     - A72 : ... < 1 year \n",
    "#     - A73 : 1 <= ... < 4 years \n",
    "#     - A74 : 4 <= ... < 7 years \n",
    "#     - A75 : .. >= 7 years \n",
    "\n",
    "# - Attribute 8: (numerical) **Installment rate in percentage of disposable income** \n",
    "  \n",
    "#  - Attribute 9: (qualitative) **Personal status and sex** \n",
    "#     - A91 : male : divorced/separated\n",
    "#     - A92 : female : divorced/separated/married\n",
    "#     - A93 : male : single\n",
    "#     - A94 : male : married/widowed\n",
    "#     - A95 : female : single \n",
    "\n",
    "# - Attribute 10: (qualitative) **Other debtors / guarantors**\n",
    "#    - A101 : none\n",
    "#    - A102 : co-applicant\n",
    "#    - A103 : guarantor \n",
    "\n",
    "# - Attribute 11: (numerical) **Present residence since**\n",
    "  \n",
    "# - Attribute 12: (qualitative) **Property**\n",
    "#     - A121 : real estate\n",
    "#     - A122 : if not A121 : building society savings agreement/ life insurance\n",
    "#     - A123 : if not A121/A122 : car or other, not in attribute 6 \n",
    "#     - A124 : unknown / no property \n",
    "\n",
    "# - Attribute 13: (numerical) **Age in years** \n",
    "  \n",
    "# - Attribute 14: (qualitative) **Other installment plans** Otros pagos por plazos\n",
    "#      - A141 : bank\n",
    "#      - A142 : stores\n",
    "#      - A143 : none \n",
    "\n",
    "# - Attribute 15: (qualitative) **Housing**\n",
    "#      - A151 : rent \n",
    "#      - A152 : own\n",
    "#      - A153 : for free \n",
    "\n",
    "# - Attribute 16: (numerical) **Number of existing credits at this bank**\n",
    "  \n",
    "# - Attribute 17: (qualitative) **Job**\n",
    "#   - A171 : unemployed/ unskilled - non-resident\n",
    "#   - A172 : unskilled - resident\n",
    "#   - A173 : skilled employee / official\n",
    "#   - A174 : management/ self-employed/highly qualified employee/ officer \n",
    "\n",
    "# - Attribute 18: (numerical) **Number of people being liable to provide maintenance for** \n",
    "  \n",
    "# - Attribute 19: (qualitative) **Telephone**\n",
    "#   - A191 : none\n",
    "#   - A192 : yes, registered under the customers name \n",
    "\n",
    "# - Attribute 20: (qualitative) **foreign worker** \n",
    "#   - A201 : yes \n",
    "#   - A202 : no \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Analisis univariante y de asociación con la variable objetivo de las **variables categóricas**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **status.of.existing.checking.account**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['status.of.existing.checking.account'].value_counts(normalize=True,dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctabla=pd.crosstab(dt['status.of.existing.checking.account'],dt['y'],margins=True).round(3)\n",
    "ctabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square test of independence. \n",
    "c, p, dof, expected = chi2_contingency(ctabla) \n",
    "# Print the p-value\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dt['status.of.existing.checking.account'],dt['y'],margins=True, normalize=1).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dt['status.of.existing.checking.account'],dt['y'],margins=True, normalize=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dt['status.of.existing.checking.account'],dt['y'],margins=True, normalize=0).round(3).plot(figsize=(15,5))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Personal status and sex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['personal.status.and.sex'].value_counts(normalize=True,dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctabla=pd.crosstab(dt['personal.status.and.sex'],dt['y'],margins=True).round(3)\n",
    "ctabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dt['personal.status.and.sex'],dt['y'],margins=True, normalize=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square test of independence. \n",
    "c, p, dof, expected = chi2_contingency(ctabla) \n",
    "# Print the p-value\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dt['personal.status.and.sex'],dt['y'],margins=True, normalize=0).round(3).plot(figsize=(15,5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Housing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['housing'].value_counts(normalize=True,dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctabla=pd.crosstab(dt['housing'],dt['y'],margins=True).round(3)\n",
    "ctabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dt['housing'],dt['y'],margins=True, normalize=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square test of independence. \n",
    "c, p, dof, expected = chi2_contingency(ctabla) \n",
    "# Print the p-value\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dt['housing'],dt['y'],margins=True, normalize=0).round(3).plot(figsize=(15,5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Job**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['job'].value_counts(normalize=True,dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctabla=pd.crosstab(dt['job'],dt['y'],margins=True).round(3)\n",
    "ctabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dt['job'],dt['y'],margins=True, normalize=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square test of independence. \n",
    "c, p, dof, expected = chi2_contingency(ctabla) \n",
    "# Print the p-value\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dt['job'],dt['y'],margins=True, normalize=0).round(3).plot(figsize=(15,5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ....  Habría que seguir haciendo esto con todas las variables categóricas para analizar asociación"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis univariante y de asociación con la variable objetivo de las **Variables continuas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Credit.amount**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(x=(dt['credit.amount']), kind=\"kde\", fill=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(x=np.log(dt['credit.amount']), kind=\"kde\", fill=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['credit.amount']=np.log(dt['credit.amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(x=(dt['credit.amount']), kind=\"kde\", fill=True, hue=dt.y, common_norm=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvalue, pvalue = f_oneway(dt.loc[dt[\"y\"]==0,['credit.amount']], dt.loc[dt[\"y\"]==1,['credit.amount']])\n",
    "print(fvalue, pvalue)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **duration.in.month**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(x=(dt['duration.in.month']), kind=\"kde\", fill=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(x=(dt['duration.in.month']), kind=\"kde\", fill=True, hue=dt.y, common_norm=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvalue, pvalue = f_oneway(dt.loc[dt[\"y\"]==0,['duration.in.month']], dt.loc[dt[\"y\"]==1,['duration.in.month']])\n",
    "print(fvalue, pvalue)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendría que continuar con el análisis del resto de variables continuas ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(dt, hue=\"y\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Selección de Variables**: análisis de Concentración para seleccionar las variables más **importantes** para meter en el modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividimos la muestra en entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train, dt_test = train_test_split(dt,stratify=dt[\"y\"], test_size=.25, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train[\"y\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train[\"y\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_test[\"y\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_test[\"y\"].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defino la tramificación óptima"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tramificación de la Variable: \"credit.amount\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable=\"credit.amount\"\n",
    "X=dt_train[variable].values\n",
    "Y=dt_train['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optb = OptimalBinning(name=variable, dtype=\"numerical\", solver=\"cp\")\n",
    "\n",
    "# Si se quisiese fijar los intervalos manualmente (porque no gusten los que obtine el agoritmo, entonces habría que usar:\n",
    "#                     user_splits=\n",
    "#                     user_splits_fixed=\n",
    "# HAy veces que los datos tienen dátos missing y códigos especiales en este caso para obtener una categoría con esos datos missing y datos especiales hay que establecerlos\n",
    "#                     special_codes = [-9, -8, -7]\n",
    "\n",
    "# Una vez definido podemos pasar a estimarlo\n",
    "optb.fit(X, Y)\n",
    "optb.splits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: Por defecto se utiliza un arbol de clasificación para hacer una tramificación inicial, y después se aplica un proceso de optimización de agrupación de categorías para maximizar el Valor de Información "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez realizado el proceso de tramificación y agrupación óptima de categorías, obtenemos la tabla de agrupación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table = optb.binning_table\n",
    "binning_table.build()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cabe mencionar que el WOE en esta tabla parece estar definido al revés que lo hemos hecho en clase, por lo que el signo es justo el contrario al que cabría esperar según lo que hemos visto en clase. En particular por defecto `optbinning` define el WOE de una categoría $i$ como\n",
    "$$ WOE_i =  ln \\left ( {Non-event_i \\over Non-event_{total}} \\over {Event_i \\over Event_{total}}    \\right ) $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este sentido los niveles con mayor tasa de impagados tendrán un WOE menos, y a medida que se reduzca la tasa de impagados (mejor calidad crediticia) irá aumentando el WOE. De hecho, 'optbinning' ni siquiera utiliza la misma fórmula que yo he utilizado en clase, por lo que no está acotada entre cero y uno, puede valos más que uno sin que eso signifique sobre ajuste.\n",
    "\n",
    "Por talmotivo utilizaremos como criterio de selección exclusivamente IV<0.002"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos extraer el IV y el índice de Gini a partir de la tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IV= \", binning_table.iv.round(3))\n",
    "print(\"Gini= \", binning_table.gini.round(3))\n",
    "\n",
    "# La última columna muestra el estadístico Jensen-Shannon de divergencia.\n",
    "# Es una medida de la similaridad entre dos distribuciones de probabilidad (frecuencias de buenos y malos )\n",
    "# que está acotada entre 0 y log2 (aprox 0.70) (puede utilizarse 0.01 como mínimo) \n",
    "print(\"JS= \", binning_table.js.round(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos profundizar en el análisis estimando otras\n",
    "binning_table.analysis(pvalue_test=\"chi2\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por ejemplo otra medida que suele utilizarse en el Quality score(QS) que está acotada entre 0 y 1 (puede utilizarse 0.01 como mínimo)\n",
    "print(\"QS= \", binning_table.quality_score.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La tabla anterior también muestra la V de Cramer (por encima de 0.20 podría ser suficiente para decir que hay asociación, \n",
    "\n",
    "# pero también podemos realizar el test con la tabla de contigencia completa:Jensen-Sha\n",
    "x_transform_indices = optb.transform(X, metric=\"indices\")\n",
    "\n",
    "#pd.Series(x_transform_indices).value_counts(normalize=True,dropna=False).sort_index()\n",
    "ctabla=pd.crosstab(pd.Series(x_transform_indices),Y,margins=True).round(3)\n",
    "print(ctabla)\n",
    "\n",
    "# Chi-square test of independence. Ho: Ausencia de Asociación (independencia)\n",
    "c, p, dof, expected = chi2_contingency(ctabla) \n",
    "# Print the p-value\n",
    "print(\"Test independencia. Estadístico :\" ,round(c,3), \"p-valor:\", round(p,3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos realizar una representación gráfica de la Tabla de tramificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table.plot(metric=\"woe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table.plot(metric=\"event_rate\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que la relación entre lavariable x (credit.amount) y la tasa de evento (impago) es **no-lineal**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos aplicar esta tramificación óptima a la variable original y obtener la variable transformada WOE (que será una variable continua que utilizaremos en el modelode regresión)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación WOE\n",
    "x_woe = optb.transform(X, metric=\"woe\")\n",
    "pd.Series(x_woe).value_counts().sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fíjate que ahora hemos conseguido \"linealizar\" la relación entre la variable trasnformada Woe y la propensión al impago "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(x_woe,Y,normalize=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(pd.crosstab(x_woe,Y,normalize=0).iloc[:,1])\n",
    "ax.set_xlabel(\"x_woe\")\n",
    "ax.set_ylabel(\"porcentaje de impago\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que para hacer la validación deberíamos hacer exactamente la misma transformación WOE, con la misma tramificación, al conjunto test. Para ello debemos aplicar la transformación optima calculada con el conjunto de entrenamiento, pero sobre la muestra de validación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación WOE en el conjunto test\n",
    "x_test_woe = optb.transform(dt_test[variable].values, metric=\"woe\")\n",
    "pd.Series(x_test_woe).value_counts().sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que **no** estamos calculando una nueva tramificación para el conjunto de test, sino aplicando la tramificación obtenida con el conjunto de entrenamiento.    \n",
    "En realidad si hiciéramos una tramificación óptima con el conjunto de test no tendría porqué salir igual que la estimada para el conunto de entrenamiento, como se puede comprobar a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable=\"credit.amount\"\n",
    "X_test=dt_test[variable].values\n",
    "Y_test=dt_test['y'].values\n",
    "optb_test = OptimalBinning(name=variable, dtype=\"numerical\")\n",
    "optb_test.fit(X_test, Y_test)\n",
    "print(optb_test.splits)\n",
    "binning_table_test = optb_test.binning_table\n",
    "binning_table_test.build()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que con el conjunto de test se han obtenido sólo 6 tramos y con diferentes puntos de corte ( y diferentes WOE), por eso es necesario no hacer una nueva tramificación al conjnto de test sino aplicar la tramificación obtenida usando en el conjunto de entrenamiento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tramificación de la duración en meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable=\"duration.in.month\"\n",
    "X=dt_train[variable].values\n",
    "Y=dt_train['y'].values\n",
    "\n",
    "optb = OptimalBinning(name=variable, dtype=\"numerical\", solver=\"cp\")\n",
    "\n",
    "optb.fit(X, Y)\n",
    "optb.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table = optb.binning_table\n",
    "binning_table.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IV= \", binning_table.iv.round(3))\n",
    "print(\"Gini= \", binning_table.gini.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table.plot(metric=\"woe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table.plot(metric=\"event_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación WOE\n",
    "x_woe = optb.transform(X, metric=\"woe\")\n",
    "pd.Series(x_woe).value_counts().sort_index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrupción de niveles en variables Vbles Categóricas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En realidad, cuando tenemosvariables categóricas, no es necesario tramificar, pero sí hacer una agrupación de los diferentes niveles de forma que se maximice el *valor de información*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupación de la variable  *purpose*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_cat = \"purpose\"\n",
    "X_cat = dt_train[variable_cat].values\n",
    "Y_cat = dt_train['y'].values\n",
    "\n",
    "dt_train[variable_cat].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optb = OptimalBinning(name=variable_cat, dtype=\"categorical\", solver=\"cp\",\n",
    "                      cat_cutoff=0.1)  # podemos cambiar los valores por defecto cat_cutoff=None, o, cat_cutoff=0.005\n",
    "\n",
    "optb.fit(X_cat, Y_cat)\n",
    "optb.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table = optb.binning_table\n",
    "binning_table.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table.plot(metric=\"event_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_woe = optb.transform(X_cat, metric=\"woe\")\n",
    "pd.Series(x_woe).value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "__________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "__________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "__________________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso de tramificación, agrupación y trasformación WOE Completo\n",
    "\n",
    "Para no ir variable a variable se puede hacer todo el proceso completo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceso Entero\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Definimos la lista de nombres señalando cualse de ellas son las categóricas\n",
    "Y = dt_train['y'].values\n",
    "X = dt_train.drop(columns=['y']) #todas menos la primera que es el ID y la variable y\n",
    "list_variables = X.columns.values.tolist()\n",
    "list_categorical = X.select_dtypes(include=['object', 'category']).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Definimos el criterio de selección\n",
    "selection_criteria = {\n",
    "    \"iv\": {\"min\": 0.02}  # no imponemos \"max\": 1}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En caso de que desee modificarse los valores por defecto en el proceso de tramificación de alguna variable puede hacerse en forma de diccionario\n",
    "\n",
    "binning_fit_params={\n",
    "    \"purpose\":{\"cat_cutoff\": 0.10}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Definimos el proceso de Tramificación o BinningProcess\n",
    "binning_process = BinningProcess(\n",
    "    categorical_variables=list_categorical,\n",
    "    variable_names=list_variables,\n",
    "    selection_criteria=selection_criteria,\n",
    "    binning_fit_params=binning_fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Obtenemos los tramos optimos de todas las Variables\n",
    "dt_train_binned = binning_process.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train_binned.summary().sort_values('iv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora podemos ir sacando las tablas para cada variable\n",
    "\n",
    "dt_train_binned.get_binned_variable(\"credit.amount\").binning_table.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train_binned.get_binned_variable(\"purpose\").binning_table.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train_binned.information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# las variables seleccionadas se pueden obtener con 'get_support'\"Tarea Estudiantes_TarjetaPuntuacion\"\n",
    "dt_train_binned.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos transformar las variables WOE\n",
    "dt_train_woe=dt_train_binned.transform(X, metric=\"woe\")\n",
    "\n",
    "\n",
    "# Existe la posibilidad de obtener directamente las transformada si en lugar de usar fit, hubiésemos usado fit_transform \n",
    "# dt_train_binned = binning_process.fit_transform(X, Y)\n",
    "# dt_train_binned.info()\n",
    "# el resultado sería un data.frame con las X seleccionadas trasnsformadas WOE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train_woe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train_woe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora aplicaríamos la misma transformación pero al conjunto de test (si hubiera que puntuar a nuevos clientes haríamos lo mismo)\n",
    "\n",
    "Y_test = dt_test['y'].values\n",
    "X_test = dt_test.drop(columns=['y']) #todas menos la primera que es el ID y la variable y\n",
    "\n",
    "dt_test_woe=dt_train_binned.transform(X_test, metric=\"woe\")\n",
    "dt_test_woe.info()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_test_woe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimación del Modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos calcular la tarjeta de puntuación. En los apuntes de clase definimos tanto los WOE, como los Odd ratio como la probabilidad de `evento` respecto al `no-evento` (malos clientes o impago=1 respecto a los buenos clientes o impago=0):\n",
    "\n",
    "$$ odd = {{P}\\over {(1-P)}} ~~ {,~~  siendo} ~~  {P=Prob(impago=1)} $$\n",
    " \n",
    " Y la fórmula para obtener la puntuación o los score debe ser una relación negativa con los odd ratio: cuanto mayor la probabilidad de impago (en relación a la de no impago), menor puntuación ha de tener: \n",
    "\n",
    " $$ score {= offset - Factor}~·~{ln(odds)}$$\n",
    "\n",
    "Para pasar de Probabiliddes de impago a Puntuaciones, habrá que establecer tanto el valor de `offset` como el de `Factor`. Esto se hace de manera arbitraria dependiendo de cada institución financiera.\n",
    "\n",
    "En general, para determinar estos dos valores es necesario establecer la pendiente de la recta y un punto de la misma.\n",
    "\n",
    "En cuanto a la pendiente, cuanto más plana sea la pendiente, menor variabilidad tendrán los valores de puntuación de crédito que se alcancen, y al revés, cuanto mayor pendiente más diferencias en la puntuación final. Yo voy a utilizar un apendiente (arbitraria) estableciendo de forma arbitraria cada cuantos puntos de score (**pdo_0**) se dobla el odd ratio: $ score - pdo_0 = {offset -Factor}~ ·{ln(2*odds)}$.\n",
    "\n",
    " En cuanto al punto de la recta (arbitrario), puede hacerse estableciento (de manera arbitraria) la puntuación o score considerada como de sobresaliente(**scorecard_points**) y el odd ratio que debería tener ese cliente de *sobresaliente* (**odds_0**)\n",
    " \n",
    " Así habría que establecer tres parámetros para transformar probabilidades de impago a puntuaciones, por ejemplo:   \n",
    "\n",
    "* **pdo_0** =40  (esto es que cada 40 puntos de calidad creditica se dobla el odd-ratio))\n",
    "* **scorecard_points** =600  (alguien con calidad crediticia muy buena, de sobresaliente, sacaría 600 puntos)\n",
    "* **odds_0** =1/50  (odd ratio que se considera de sobresaliente)\n",
    "\n",
    "La librería `optBinning` [librería OptBinning](http://gnpalencia.org/optbinning/), en realidad utiliza el módulo de `credit scoring` de `SAS-miner` como inspiración, y por eso define al revés tanto los WOE como los odd ratio, es decir `no-evento` en relación a `evento` (clientes buenos respecto a los malos, o no-impago respecto a impago, impago=0 respecto a impago=1). \n",
    "$$ odd^B = {{(1-P)}\\over {P}} ~~ {,~~  siendo} ~~  {P=Prob(impago=1)} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto implica que la ecuación que transforma las probabilidades de impago en scores utilizando esta *odds<sup>B</sup>* debe tener pendiente positiva (cuanto mejor *odd<sup>B</sup>* mejor calidad crediticia tiene el cliente)\n",
    "\n",
    " $$ score= {offset + Factor} ~·~ {ln(odds^B)}$$\n",
    " \n",
    " Nótese que ahora habrá que establecer de nuevo los puntos de score que doblan el odd ratio (**pdo_0**), y también la puntuación o score considerada como de sobresaliente(**scorecard_points**) y el odd ratio que debería tener ese cliente de *sobresaliente* **odds_0 <sup>*B*</sup>**, con **odds_0 <sup>*B*</sup>** **= 1/odds_0**.\n",
    "\n",
    " Así para estimar la puntuación crediticia con `optBinning` hay que establecer tres parámetros para transformar probabilidades de impago a puntuaciones, por ejemplo:   \n",
    "\n",
    "* **pdo_0** =40\n",
    "* **scorecard_points** =600 \n",
    "* **odds_0 <sup>*B*</sup>** = 50  (equivalente a **odds_0** =1/50 )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directamente con el método Scorecard\n",
    "estimator = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "# Establecemos los parámetros para la transformación de probabilidades en puntos de calidad crediticia o score\n",
    "\n",
    "pdo_0 =40\n",
    "scorecard_points_0= 600 \n",
    "odds_0_B= 50 # (equivalente a  odds_0 =1/50 )\n",
    "\n",
    "tarjeta= Scorecard(binning_process=binning_process,\n",
    "                   estimator=estimator,\n",
    "                   scaling_method=\"pdo_odds\",\n",
    "                   scaling_method_params={\"pdo\":pdo_0, \"odds\": odds_0_B, \"scorecard_points\": scorecard_points_0})\n",
    "\n",
    "tarjeta.fit(X, Y, show_digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarjeta.information(print_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarjeta.table(style=\"detailed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenmos las predicciones\n",
    "Y_pred=tarjeta.predict_proba(X)[:,1]\n",
    "\n",
    "# Calculamos la media\n",
    "Y_pred.mean().round(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para contruir las matrices de confusión necesitamos determinar un\n",
    "# **punto de corte de la probabilidad**.\n",
    "# Ese punto de corte es el que me va a ayudar a realizar un pronóstico sobre los clientes:\n",
    "# los malos clientes serán aquelloe para los que Prob Estimada > Prob_corte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para elegir el punto de corte puede utilizarse el Plot Kolmogorov-Smirnov (KS)\n",
    "plot_ks(Y, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# También puede utilizarse el máximo del f1_score\n",
    "# definimos un vector de puntos de corte\n",
    "c=np.arange(0,1,0.01)\n",
    "# calculamos el f1_score para cada punto de corte\n",
    "f1_score_ = [f1_score(dt_train[\"y\"],np.multiply(Y_pred>c_,1)) for c_ in c]\n",
    "# obtenemos el punto de corte que maximiza el f1_score\n",
    "c_max = c[np.argmax(f1_score_)]\n",
    "print(\"El punto de corte que maximiza el f1_score es: \", c_max)\n",
    "print(\"y el máximo se alcanza en \", np.max(f1_score_).round(3))\n",
    "\n",
    "# hacemos un gráfico de c y los f1_score correspondientes\n",
    "plt.plot(c,f1_score_)\n",
    "plt.stem(c_max, np.max(f1_score_),linefmt='r--', markerfmt='ro', basefmt='r--')\n",
    "plt.title(\"Gráfico f1_score vs diferentes puntos de corte\")\n",
    "plt.text(c_max+0.05, 0, \"c_max = \"+str(c_max.round(2))+\"\\n f1_score_max = \"+str(np.max(f1_score_).round(3)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# método de Youden (J) para obtener el punto de corte óptimo\n",
    "# definimos un vector de puntos de corte (c) y de probabilidad de aceptación (p)\n",
    "c=np.arange(0,1,0.01)\n",
    "\n",
    "# Calculamos el estadístico J de Youden para cada punto de corte= Sensibilidad + Especificidad -1\n",
    "J= [balanced_accuracy_score(dt_train[\"y\"],np.multiply(Y_pred>c_,1), adjusted=True) for c_ in c ]\n",
    "# obtenemos el punto de corte que maximiza el índice de Youden\n",
    "c_max = c[np.argmax(J)]\n",
    "print(\"El punto de corte que maximiza el índice de Youden es: \", c_max)\n",
    "print(\"y el máximo se alcanza en \", np.max(J).round(3))\n",
    "\n",
    "# gráfico de c y los índices de Youden correspondientes\n",
    "plt.plot(c,J)\n",
    "plt.stem(c_max, np.max(J),linefmt='r--', markerfmt='ro', basefmt='r--')\n",
    "plt.title(\"Gráfico índice de Youden vs diferentes puntos de corte\")\n",
    "plt.text(c_max+0.05, 0, \"c_max = \"+str(c_max.round(2))+\"\\n J_max = \"+str(np.max(J).round(3)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voy a utilizar simplemente la frecuencia observada\n",
    "Prob_Corte=Y.mean()\n",
    "print(Prob_Corte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train[\"Y_pronostico\"]=np.multiply(Y_pred>Prob_Corte,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para comprobar la bondad de nuestras predicciones voy a comparar resultados con la tabla de confusión\n",
    "\n",
    "# Primero estimo la precisión (los aciertos sobre el total de mis pronósticos)\n",
    "pd.crosstab(dt_train[\"y\"],dt_train[\"Y_pronostico\"],margins=True, normalize=1).round(3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que los falsos negativos (Bad Rate) es del 11.5% (préstamos aceptados o pronosticados como buenos que resultaron impagados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora estimo la exhaustividad o recall (Aciertos sobre los casos reales):\n",
    "# la sensibilidad (sobre los positivos y=1), y la Especificidad (sobre los negativos y=0)\n",
    "\n",
    "pd.crosstab(dt_train[\"y\"],dt_train[\"Y_pronostico\"],margins=True, normalize=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por último un resumen global de aciertos\n",
    "f1_score(dt_train[\"y\"],dt_train[\"Y_pronostico\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer la diagnosis también puedo utilizar medidas que no dependan crucialmente de un único punto de corte de Probabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosis Curva ROC\n",
    "plot_auc_roc(Y,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosis Cumulative Accuracy Profile (CAP)\n",
    "# Otra curva alternativa a la curva ROC que permite evaluar la bondad de un modelo de clasificación es la curva CAP (Cumulative Accuracy Profile).\n",
    "# La curva CAP se construye de la siguiente manera: ordenamos las observaciones de mayor a menor probabilidad\n",
    "# de pertenecer a la clase positiva (y=1). A continuación, vamos acumulando las observaciones y calculando\n",
    "# la proporción de positivos acumulados sobre el total de positivos. Esta proporción se representa en el eje Y.\n",
    "\n",
    "# En el eje X representamos la proporción de observaciones acumuladas sobre el total de observaciones.\n",
    "# La curva CAP se construye a partir de la curva de la línea recta (curva de referencia) y \n",
    "# la curva de la línea que representa la probabilidad estimada por el modelo.\n",
    "\n",
    "plot_cap(Y, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### OJO que la diagnosis debe hacerse fuera de la muestra de entrenamiento\n",
    "# obtenmos las predicciones\n",
    "Y_test_pred=tarjeta.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculamos la media\n",
    "Y_test_pred.mean().round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosis Curva ROC\n",
    "plot_auc_roc(Y_test,Y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cap(Y_test,Y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_test[\"Y_pronostico\"]=np.multiply(Y_test_pred>Prob_Corte,1)\n",
    "\n",
    "# Primero estimo la precisión (los aciertos sobre el total de mis pronósticos)\n",
    "print(\"\\n Precisión:\\n\", pd.crosstab(dt_test[\"y\"],dt_test[\"Y_pronostico\"],margins=True, normalize=1).round(3))\n",
    "\n",
    "# Ahora estimo la exhaustividad o recall (Aciertos sobre los casos reales):\n",
    "# la sensibilidad (sobre los positivos y=1), y la Especificidad (sobre los negativos y=0)\n",
    "print(\"\\n exhaustividad:\\n\",pd.crosstab(dt_test[\"y\"],dt_test[\"Y_pronostico\"],margins=True, normalize=0).round(3))\n",
    "\n",
    "# Por último un resumen global de aciertos\n",
    "print(\"\\n f1-score:\",f1_score(dt_test[\"y\"],dt_test[\"Y_pronostico\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora vamos a calcular los score o puntuaciones.\n",
    "#Que podemos hacer  con la función score\n",
    "score = tarjeta.score(X)\n",
    "\n",
    "print(\"Puntuación mínima: \", score.min().round(2))\n",
    "print(\"Puntuación máxima: \",score.max().round(2))\n",
    "print(\"Puntuación media : \",score.mean().round(2))  \n",
    "\n",
    "\n",
    "# Transformación lineal según apuntes\n",
    "# Factor= (pdo_0/log(2))\n",
    "# Offset = scorecard_points_0+(pdo_0/log(2))*log(odds0_0)\n",
    "# score= Offset - Factor *log(odds)\n",
    "\n",
    "Factor= (pdo_0/np.log(2))\n",
    "Offset = scorecard_points_0+Factor*np.log(1/odds_0_B)\n",
    "\n",
    "#Podríamos haber calculado la puntuación también manualmente\n",
    "score2= Offset-Factor*np.log(Y_pred/(1-Y_pred))\n",
    "\n",
    "# Podemos comprobar que los resultados son los mismos   \n",
    "print(\"Puntuación mínima: \",score2.min().round(2))\n",
    "print(\"Puntuación máxima: \",score2.max().round(2))\n",
    "print(\"Puntuación media : \",score2.mean().round(2))\n",
    "\n",
    "datos_score=pd.DataFrame(np.transpose([score,score2, Y,Y_pred]), columns=['score','scoreManual','Y','Y_pred'])\n",
    "\n",
    "# datos_score.to_excel(\"score_p1.xlsx\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saber cómo se hace la transformación manual puede ayudarnos por ejemplo a la hora de establecer la `nota que determina el aprobado`. Imaginemos que utilizamos la frecuencia observada de impagos como probabilidad de corte "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Score_Corte= Offset-Factor*np.log(Prob_Corte/(1-Prob_Corte))\n",
    "\n",
    "print(\"La probabilida de corte de: \", Prob_Corte, \" equivale a una puntuación de corte de: \", Score_Corte.round(2) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora representamos en un gráfico cómo separa el modelo a los buenos y los malos\n",
    "datos_score=pd.DataFrame(np.transpose([score,Y]), columns=['score','Y'])\n",
    "sns.displot(data=datos_score, x='score', label=\"event\", hue='Y', alpha=0.35,kind=\"kde\", fill=True, common_norm=True)\n",
    "plt.axvline(Score_Corte, color='k', linestyle=\":\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seguimiento del modelo: PSI (Population Stability Index)\n",
    "El PSI es una medida de diferencia en la distribución de dos muestras, en nuestro caso entre la muestra utilizada para construir el modelo (entrenar y validar el modelo), y los nuevos datos que se vayan obteniendo con el transcurso del tiempo.  \n",
    "\n",
    "Se aplica para detectar cuándo comienzan a verse diferencias entre las dos muestras (las puntuaciones de la muestra -train- y las puntuaciones obtenidas con los nuevos datos .... Cuando las distribuciones dejen de parecerse será el momento de revisar el modelo a tenor de los nuevos datos \n",
    "\n",
    "Como regla general \n",
    "  - **PSI <0.1**: No hay diferencias significativas entre las muestras de entrenamiento y los nuevos datos (resultado deseado, no se requiere más acciones)\n",
    "  - **PSI entre 0.1 y 0.25** Hay cambio menores, valdría la pena revisar el modelo\n",
    "  - **PSI >0.25** hay cambios importantes entre las dos muestras HAY QUE CAMBIAR EL MODELO \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que tenemos un conjunto de nuevos datos que hemos ido recopilando después de la puesta en producción del modelo,\n",
    "# y queremos utilizar esos nuevos datos para saber si es necesario revisar el modelo o si por el contrario podemos seguir utilizándolo\n",
    "\n",
    "# Como en la base de datos no disponemos de este tipo de datos voy a suponer simplemente que los datos de test son los nuevos datos,\n",
    "\n",
    "dt_nuevosdatos= dt_test.copy() \n",
    "\n",
    "\n",
    "from optbinning.scorecard import plot_auc_roc, plot_cap, plot_ks,ScorecardMonitoring\n",
    "\n",
    "\n",
    "# Valores nuevos\n",
    "Y_nuevo = dt_nuevosdatos['y'].values\n",
    "X_nuevo = dt_nuevosdatos.drop(columns=['y']) #todas menos la primera que es el ID y la variable y\n",
    "\n",
    "# Valores de entrenamiento\n",
    "Y = dt_train['y'].values\n",
    "X = dt_train.drop(columns=['y']) #todas menos la variable y\n",
    "\n",
    "\n",
    "# ¿se distibuyen igual las probabilidades esperadas?\n",
    "score_train = tarjeta.score(X)\n",
    "score_nuevo = tarjeta.score(X_nuevo)\n",
    "\n",
    "datos_score_psi1=pd.DataFrame(np.transpose([score_train,Y]), columns=['score','Y'])\n",
    "datos_score_psi1['tipo']='entrenamiento'\n",
    "\n",
    "datos_score_psi2=pd.DataFrame(np.transpose([score_nuevo,Y_nuevo]), columns=['score','Y'])\n",
    "datos_score_psi2['tipo']='nuevos datos'\n",
    "\n",
    "datos_score_psi= pd.concat([datos_score_psi1,datos_score_psi2])\n",
    "sns.displot(data=datos_score_psi, x='score', label=\"event\", hue='tipo', alpha=0.35,kind=\"kde\", fill=True,common_norm=False)\n",
    "plt.axvline(Score_Corte, color='k', linestyle=\":\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Estimo el psi\n",
    "# Defino la tarjeta a evalear\n",
    "psi=ScorecardMonitoring(tarjeta, psi_method=\"cart\",psi_min_bin_size=0.10, psi_n_bins=20)\n",
    "#psi=ScorecardMonitoring(tarjeta, psi_method= \"quantile\", psi_n_bins=10)\n",
    "\n",
    "\n",
    "psi.fit(X_actual=X_nuevo, y_actual=Y_nuevo, X_expected=X, y_expected=Y)\n",
    "\n",
    "psi.psi_plot()\n",
    "psi.psi_table()\n",
    "psi.tests_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi.system_stability_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi.psi_variable_table(style=\"summary\").sort_values('PSI')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5043996dbb5012f6a1a52b57fe18efa9888e0de81faf0d7ab7fe229615f6c3c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
